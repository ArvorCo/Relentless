# Implementation Plan: Smart Auto Model Routing

**Branch**: `002-smart-auto-model` | **Date**: 2026-01-19 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/relentless/features/002-smart-auto-model/spec.md`

---

## Summary

Smart Auto Model Routing enables cost-optimal task execution by routing tasks to appropriate AI models based on complexity classification. The system provides four opinionated modes (`--mode free|cheap|good|genius`), supports all 6 harnesses (Claude, Codex, Droid, OpenCode, Amp, Gemini) with configurable fallback order, and breaks final review into micro-tasks to prevent context window bloat.

**Key Deliverables:**
1. Harness adapter updates for model selection
2. Configuration schema for auto-mode settings
3. Model registry with capabilities and costs
4. Hybrid complexity classification (heuristics + LLM)
5. Routing logic with cascade/escalation
6. Review micro-tasks system

---

## Technical Context

**Language/Version**: TypeScript (strict mode)
**Runtime**: Bun (not Node.js)
**Primary Dependencies**: Zod (validation), Commander (CLI), existing agent adapters
**Storage**: File-based (relentless.config.yaml, prd.json, progress.txt)
**Testing**: Bun test with >80% coverage
**Target Platform**: macOS, Linux (CLI)
**Performance Goals**: Model selection <100ms, zero overhead on task execution
**Constraints**: Must work with existing orchestration loop, backward compatible
**Scale/Scope**: Support 6 harnesses, 20+ models, configurable per-project

---

## Constitution Check

**PASS** - This feature directly implements:
- âœ… **Principle 2**: Smart Model Routing (MUST evaluate complexity, route at planning time)
- âœ… **Principle 5**: Adaptive Final Review (MUST use SOTA for final review)
- âœ… **Principle 6**: Agent-Aware Best Practices (MUST maintain knowledge of capabilities)
- âœ… **Principle 1**: TDD (tests before implementation)
- âœ… **Principle 7**: Zero-lint policy (TypeScript strict, Zod schemas)

---

## Project Structure

### Documentation (this feature)

```text
relentless/features/002-smart-auto-model/
â”œâ”€â”€ spec.md              # Feature specification âœ“
â”œâ”€â”€ plan.md              # This file âœ“
â”œâ”€â”€ progress.txt         # Progress log âœ“
â””â”€â”€ tasks.md             # Generated by /relentless.tasks (next step)
```

### Source Code (repository root)

```text
src/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ schema.ts        # [MODIFY] Add AutoModeConfig, ModeModels, ReviewConfig
â”‚   â””â”€â”€ loader.ts        # [MODIFY] Load auto-mode settings
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ types.ts         # [MODIFY] Add ModelInfo, HarnessCapabilities
â”‚   â”œâ”€â”€ registry.ts      # [MODIFY] Add model registry with costs/capabilities
â”‚   â”œâ”€â”€ claude.ts        # [EXISTING] Already supports --model âœ“
â”‚   â”œâ”€â”€ codex.ts         # [MODIFY] Add model selection
â”‚   â”œâ”€â”€ droid.ts         # [MODIFY] Add -m flag for model selection
â”‚   â”œâ”€â”€ opencode.ts      # [MODIFY] Add model selection
â”‚   â”œâ”€â”€ amp.ts           # [MODIFY] Add model selection (limited)
â”‚   â””â”€â”€ gemini.ts        # [MODIFY] Add model selection
â”œâ”€â”€ routing/             # [NEW] Routing module
â”‚   â”œâ”€â”€ index.ts         # Module exports
â”‚   â”œâ”€â”€ classifier.ts    # Hybrid complexity classification
â”‚   â”œâ”€â”€ router.ts        # Model/harness selection logic
â”‚   â”œâ”€â”€ cascade.ts       # Escalation/fallback logic
â”‚   â””â”€â”€ registry.ts      # Model capability registry
â”œâ”€â”€ review/              # [NEW] Review micro-tasks module
â”‚   â”œâ”€â”€ index.ts         # Module exports
â”‚   â”œâ”€â”€ runner.ts        # Micro-task orchestration
â”‚   â”œâ”€â”€ tasks/           # Individual micro-task implementations
â”‚   â”‚   â”œâ”€â”€ typecheck.ts
â”‚   â”‚   â”œâ”€â”€ lint.ts
â”‚   â”‚   â”œâ”€â”€ test.ts
â”‚   â”‚   â”œâ”€â”€ security.ts
â”‚   â”‚   â”œâ”€â”€ quality.ts
â”‚   â”‚   â””â”€â”€ docs.ts
â”‚   â””â”€â”€ reporter.ts      # Issue reporting and fix queueing
â””â”€â”€ execution/
    â”œâ”€â”€ router.ts        # [MODIFY] Integrate auto-mode routing
    â””â”€â”€ runner.ts        # [MODIFY] Add escalation handling

tests/
â”œâ”€â”€ routing/
â”‚   â”œâ”€â”€ classifier.test.ts
â”‚   â”œâ”€â”€ router.test.ts
â”‚   â””â”€â”€ cascade.test.ts
â”œâ”€â”€ review/
â”‚   â””â”€â”€ runner.test.ts
â””â”€â”€ integration/
    â””â”€â”€ auto-mode.test.ts
```

---

## Part 1: Harness Adapter Model Selection

### 1.1 Current State Analysis

| Harness | Current Support | CLI Flag | Implementation Status |
|---------|----------------|----------|----------------------|
| Claude | âœ… Full | `--model <model>` | Ready |
| Codex | âœ… Full | `--model <model>` | Ready |
| Droid | âœ… Full | `-m <model>` | Ready |
| OpenCode | âœ… Full | `--model <provider/model>` | Ready |
| Amp | âœ… Full | `-m <mode>`, `-x` | Ready |
| Gemini | âœ… Full | `--model <model>` | Ready |

### 1.2 Harness CLI Commands for Model Selection

Each harness has its own CLI interface for model selection:

#### Claude Code
```bash
# Model selection via --model flag
claude --model opus-4-5 -p "Task description"
claude --model sonnet-4-5 -p "Task description"
claude --model haiku-4-5 -p "Task description"
```

**Available Models:**
- `opus-4-5` (claude-opus-4-5-20251101) - SOTA, $5/$25 per MTok
- `sonnet-4-5` (claude-sonnet-4-5-20251020) - Balanced, $3/$15 per MTok
- `haiku-4-5` (claude-haiku-4-5-20251022) - Fast, $1/$5 per MTok

**Adapter Update (src/agents/claude.ts:38-71):**
Already implemented - uses `options.model` to pass `--model` flag.

---

#### Codex CLI (OpenAI)
```bash
# Model selection via --model flag
codex exec --model gpt-5.2 -c reasoning_effort="low|medium|high|xhigh" -
```

**Available Models:**
- `gpt-5.2-xhigh` - Extreme reasoning tier, ~$1.75/$14 per MTok (maps to `-c reasoning_effort="xhigh"`)
- `gpt-5.2-high` - High reasoning tier, ~$1.75/$14 per MTok (maps to `-c reasoning_effort="high"`)
- `gpt-5.2-medium` - Balanced tier, ~$1.25/$10 per MTok (maps to `-c reasoning_effort="medium"`)
- `gpt-5.2-low` - Fast tier, ~$0.75/$6 per MTok (maps to `-c reasoning_effort="low"`)

**Adapter Update (src/agents/codex.ts:38-63):**
```typescript
async invoke(prompt: string, options?: InvokeOptions): Promise<AgentResult> {
  const startTime = Date.now();
  const args = ["exec"];

  if (options?.model) {
    const modelProfile = getModelById(options.model);
    if (modelProfile?.harness === "codex") {
      args.push(modelProfile.cliFlag, modelProfile.cliValue);
      if (modelProfile.cliArgs) {
        args.push(...modelProfile.cliArgs);
      }
    } else {
      args.push("--model", options.model);
    }
  }

  args.push("-");

  const proc = Bun.spawn(["codex", ...args], {
    cwd: options?.workingDirectory,
    stdin: new Blob([prompt]),
    stdout: "pipe",
    stderr: "pipe",
  });
  // ... rest unchanged
}
```

---

#### Droid
```bash
# Model selection via -m flag (short for --model)
droid exec -m gpt-5.2 --auto high
droid exec -m claude-sonnet-4-5-20250929 --auto high
droid exec -m gpt-5.1-codex --auto high
```

**Available Models:**
- `claude-opus-4-5-20251101` - Claude Opus 4.5
- `claude-sonnet-4-5-20250929` - Claude Sonnet 4.5
- `claude-haiku-4-5-20251001` - Claude Haiku 4.5
- `gpt-5.2` - GPT-5.2
- `gpt-5.1` - GPT-5.1
- `gpt-5.1-codex` - GPT-5.1 Codex
- `gpt-5.1-codex-max` - GPT-5.1 Codex Max
- `gemini-3-pro-preview` - Gemini 3 Pro Preview

**Adapter Update (src/agents/droid.ts:38-64):**
```typescript
async invoke(prompt: string, options?: InvokeOptions): Promise<AgentResult> {
  const startTime = Date.now();
  const args = ["exec"];

  if (options?.model) {
    const modelProfile = getModelById(options.model);
    const modelValue =
      modelProfile?.harness === "droid" ? modelProfile.cliValue : options.model;
    args.push("-m", modelValue);
    if (modelProfile?.harness === "droid" && modelProfile.cliArgs) {
      args.push(...modelProfile.cliArgs);
    }
  }

  args.push("--auto", "high");

  const proc = Bun.spawn(["droid", ...args], {
    cwd: options?.workingDirectory,
    stdin: new Blob([prompt]),
    stdout: "pipe",
    stderr: "pipe",
  });
  // ... rest unchanged
}
```

---

#### OpenCode Zen
```bash
# Model selection via --model flag
opencode run --model glm-4.7 "Task description"
opencode run --model grok-code-fast-1 "Task description"
opencode run --model minimax-m2.1 "Task description"
```

**Available Models (Free Tier):**
- `glm-4.7` - Best multilingual/backend, 73.8% SWE-bench
- `grok-code-fast-1` - Fastest (92 tok/s), great for agentic
- `minimax-m2.1` - Best full-stack (88.6 VIBE)

**Adapter Update (src/agents/opencode.ts:38-62):**
```typescript
async invoke(prompt: string, options?: InvokeOptions): Promise<AgentResult> {
  const startTime = Date.now();
  const args = ["run"];

  if (options?.model) {
    const modelProfile = getModelById(options.model);
    if (modelProfile?.harness === "opencode") {
      args.push("--model", modelProfile.cliValue);
      if (modelProfile.cliArgs) {
        args.push(...modelProfile.cliArgs);
      }
    } else {
      args.push("--model", options.model);
    }
  }

  args.push(prompt);

  const proc = Bun.spawn(["opencode", ...args], {
    cwd: options?.workingDirectory,
    stdout: "pipe",
    stderr: "pipe",
  });
  // ... rest unchanged
}
```

---

#### Amp
```bash
# Amp uses -m for mode selection and -x for execute mode
amp -m smart -x --dangerously-allow-all "Task description"
amp -m free -x --dangerously-allow-all "Task description"
```

**Available Modes:**
- `smart` - Default, uses best available
- `free` - $10/day grant with ads

**Adapter Update (src/agents/amp.ts:38-67):**
```typescript
async invoke(prompt: string, options?: InvokeOptions): Promise<AgentResult> {
  const startTime = Date.now();
  const args: string[] = [];

  if (options?.dangerouslyAllowAll) {
    args.push("--dangerously-allow-all");
  }

  if (options?.model) {
    args.push("-m", options.model);
  }

  args.push("-x");

  const proc = Bun.spawn(["amp", ...args], {
    cwd: options?.workingDirectory,
    stdin: new Blob([prompt]),
    stdout: "pipe",
    stderr: "pipe",
  });
  // ... rest unchanged
}
```

---

#### Gemini
```bash
# Gemini uses --model flag
gemini --model gemini-3-pro "Task description"
gemini --model gemini-3-flash "Task description"
```

**Available Models:**
- `gemini-3-pro` - WebDev Arena leader, $2-4/$12-18 per MTok
- `gemini-3-flash` - Fast, low-cost, $0.50/$3 per MTok

**Adapter Update (src/agents/gemini.ts):**
```typescript
async invoke(prompt: string, options?: InvokeOptions): Promise<AgentResult> {
  const startTime = Date.now();
  const args: string[] = [];

  if (options?.model) {
    args.push("--model", options.model);
  }

  args.push(prompt);

  const proc = Bun.spawn(["gemini", ...args], {
    cwd: options?.workingDirectory,
    stdout: "pipe",
    stderr: "pipe",
  });
  // ... rest unchanged
}
```

---

## Part 2: Configuration Schema

### 2.1 Zod Schema Extensions (src/config/schema.ts)

```typescript
import { z } from "zod";

// Mode options
const ModeSchema = z.enum(["free", "cheap", "good", "genius"]);

// Complexity levels
const ComplexitySchema = z.enum(["simple", "medium", "complex", "expert"]);

// Harness names with order
const HarnessNameSchema = z.enum([
  "claude", "codex", "droid", "opencode", "amp", "gemini"
]);

// Model mapping per complexity level
const ModeModelsSchema = z.object({
  simple: z.string(),
  medium: z.string(),
  complex: z.string(),
  expert: z.string(),
});

// Review micro-task types
const ReviewTaskSchema = z.enum([
  "typecheck", "lint", "test", "security", "quality", "docs"
]);

// Review configuration
const ReviewConfigSchema = z.object({
  promptUser: z.boolean().default(true),
  defaultMode: ModeSchema.default("good"),
  microTasks: z.array(ReviewTaskSchema).default([
    "typecheck", "lint", "test", "security", "quality", "docs"
  ]),
  maxRetries: z.number().int().min(1).max(5).default(3),
});

// Escalation configuration
const EscalationConfigSchema = z.object({
  enabled: z.boolean().default(true),
  maxAttempts: z.number().int().min(1).max(5).default(3),
  escalationPath: z.record(z.string()).default({
    "haiku-4.5": "sonnet-4.5",
    "sonnet-4.5": "opus-4.5",
    "gpt-5.2-low": "gpt-5.2-medium",
    "gpt-5.2-medium": "gpt-5.2-high",
    "gpt-5.2-high": "gpt-5.2-xhigh",
    "grok-code-fast-1": "gpt-5.2-low",
    "gemini-3-flash": "gemini-3-pro",
  }),
});

// Auto-mode configuration
const AutoModeConfigSchema = z.object({
  enabled: z.boolean().default(false),
  defaultMode: ModeSchema.default("good"),
  fallbackOrder: z.array(HarnessNameSchema).default([
    "claude", "codex", "droid", "opencode", "amp", "gemini"
  ]),
  modeModels: ModeModelsSchema.default({
    simple: "haiku-4.5",
    medium: "sonnet-4.5",
    complex: "opus-4.5",
    expert: "opus-4.5",
  }),
  review: ReviewConfigSchema.default({}),
  escalation: EscalationConfigSchema.default({}),
});

// Export types
export type Mode = z.infer<typeof ModeSchema>;
export type Complexity = z.infer<typeof ComplexitySchema>;
export type HarnessName = z.infer<typeof HarnessNameSchema>;
export type ModeModels = z.infer<typeof ModeModelsSchema>;
export type ReviewConfig = z.infer<typeof ReviewConfigSchema>;
export type EscalationConfig = z.infer<typeof EscalationConfigSchema>;
export type AutoModeConfig = z.infer<typeof AutoModeConfigSchema>;
```

### 2.2 Model Registry Schema (src/routing/registry.ts)

```typescript
import { z } from "zod";

// Model capability profile
const ModelProfileSchema = z.object({
  id: z.string(),                    // e.g., "opus-4.5"
  displayName: z.string(),           // e.g., "Claude Opus 4.5"
  harness: HarnessNameSchema,        // e.g., "claude"
  tier: z.enum(["free", "cheap", "standard", "premium", "sota"]),

  // Costs (per million tokens)
  inputCost: z.number(),             // e.g., 5.0 for $5/MTok
  outputCost: z.number(),            // e.g., 25.0 for $25/MTok

  // Capabilities and benchmarks
  sweBenchScore: z.number().optional(),  // e.g., 80.9
  contextWindow: z.number(),             // e.g., 200000
  tokensPerSecond: z.number().optional(), // e.g., 50

  // Strengths
  strengths: z.array(z.string()),    // e.g., ["code_review", "architecture"]
  limitations: z.array(z.string()),  // e.g., ["slow_start"]

  // CLI command pattern
  cliFlag: z.string(),               // e.g., "--model"
  cliValue: z.string(),              // e.g., "claude-opus-4-5-20251101"
});

// Harness capability profile
const HarnessProfileSchema = z.object({
  name: HarnessNameSchema,
  displayName: z.string(),
  models: z.array(ModelProfileSchema),
  defaultModel: z.string(),
  supportsModelSelection: z.boolean(),
  modelSelectionMethod: z.enum(["flag", "env", "config"]),
});

export type ModelProfile = z.infer<typeof ModelProfileSchema>;
export type HarnessProfile = z.infer<typeof HarnessProfileSchema>;
```

---

## Part 3: Hybrid Complexity Classification

### 3.1 Classification Algorithm (src/routing/classifier.ts)

```typescript
interface ClassificationResult {
  complexity: Complexity;
  confidence: number;      // 0.0 - 1.0
  reasoning: string;
  usedLLM: boolean;
}

// Heuristic signals for complexity
const COMPLEXITY_SIGNALS = {
  simple: {
    keywords: ["fix typo", "update docs", "add comment", "rename", "format"],
    maxLines: 50,
    maxFiles: 2,
    patterns: [/README|\.md$/i, /typo|spelling/i],
  },
  medium: {
    keywords: ["implement", "add feature", "refactor", "test"],
    maxLines: 200,
    maxFiles: 5,
    patterns: [/api|endpoint|service/i],
  },
  complex: {
    keywords: ["architecture", "integrate", "migration", "security"],
    maxLines: 500,
    maxFiles: 10,
    patterns: [/auth|oauth|jwt|encryption/i],
  },
  expert: {
    keywords: ["redesign", "performance", "distributed", "concurrent"],
    patterns: [/parallel|async|race|deadlock/i],
  },
};

async function classifyTask(task: UserStory): Promise<ClassificationResult> {
  // Step 1: Apply heuristics
  const heuristicResult = applyHeuristics(task);

  // Step 2: Check confidence
  if (heuristicResult.confidence >= 0.8) {
    // High confidence - use heuristic result directly
    return heuristicResult;
  }

  // Step 3: Ambiguous - use LLM for classification
  const llmResult = await classifyWithLLM(task, heuristicResult);
  return llmResult;
}

function applyHeuristics(task: UserStory): ClassificationResult {
  const { title, description, acceptanceScenarios } = task;
  const text = `${title} ${description} ${acceptanceScenarios.join(" ")}`.toLowerCase();

  // Score each complexity level
  let scores = { simple: 0, medium: 0, complex: 0, expert: 0 };

  for (const [level, signals] of Object.entries(COMPLEXITY_SIGNALS)) {
    // Keyword matching
    for (const keyword of signals.keywords || []) {
      if (text.includes(keyword)) scores[level] += 2;
    }

    // Pattern matching
    for (const pattern of signals.patterns || []) {
      if (pattern.test(text)) scores[level] += 3;
    }
  }

  // Find highest scoring level
  const maxScore = Math.max(...Object.values(scores));
  const winner = Object.entries(scores).find(([_, s]) => s === maxScore)?.[0] || "medium";
  const confidence = maxScore / 10; // Normalize to 0-1

  return {
    complexity: winner as Complexity,
    confidence: Math.min(confidence, 1.0),
    reasoning: `Heuristic analysis: ${winner} (score: ${maxScore})`,
    usedLLM: false,
  };
}

async function classifyWithLLM(
  task: UserStory,
  heuristic: ClassificationResult
): Promise<ClassificationResult> {
  // Use a cheap model for classification (Haiku)
  const prompt = `
Classify this task's complexity level: simple, medium, complex, or expert.

Task: ${task.title}
Description: ${task.description}
Acceptance: ${task.acceptanceScenarios.join("\n")}

Heuristic suggestion: ${heuristic.complexity} (confidence: ${heuristic.confidence})

Respond with JSON: {"complexity": "...", "reasoning": "..."}
`;

  const result = await invokeClassifier(prompt); // Uses Haiku

  return {
    complexity: result.complexity,
    confidence: 0.9, // LLM decision is high confidence
    reasoning: result.reasoning,
    usedLLM: true,
  };
}
```

---

## Part 4: Routing Logic

### 4.1 Mode-Model Matrix (src/routing/router.ts)

```typescript
// Model selection based on mode and complexity
const MODE_MODEL_MATRIX: Record<Mode, Record<Complexity, ModelSelection>> = {
  free: {
    simple: { harness: "opencode", model: "glm-4.7" },
    medium: { harness: "amp", model: "amp-free" },
    complex: { harness: "opencode", model: "grok-code-fast-1" },
    expert: { harness: "opencode", model: "grok-code-fast-1" },
  },
  cheap: {
    simple: { harness: "claude", model: "haiku-4.5" },
    medium: { harness: "gemini", model: "gemini-3-flash" },
    complex: { harness: "codex", model: "gpt-5.2-low" },
    expert: { harness: "codex", model: "gpt-5.2-low" },
  },
  good: {
    simple: { harness: "claude", model: "sonnet-4.5" },
    medium: { harness: "claude", model: "sonnet-4.5" },
    complex: { harness: "claude", model: "opus-4.5" },
    expert: { harness: "claude", model: "opus-4.5" },
  },
  genius: {
    simple: { harness: "claude", model: "opus-4.5" },
    medium: { harness: "claude", model: "opus-4.5" },
    complex: { harness: "claude", model: "opus-4.5" },
    expert: { harness: "claude", model: "opus-4.5" },
  },
};

interface RoutingDecision {
  harness: HarnessName;
  model: string;
  complexity: Complexity;
  mode: Mode;
  estimatedCost: number;
  reasoning: string;
}

async function routeTask(
  task: UserStory,
  config: AutoModeConfig
): Promise<RoutingDecision> {
  // Step 1: Classify complexity
  const classification = await classifyTask(task);

  // Step 2: Get model from matrix
  const selection = MODE_MODEL_MATRIX[config.defaultMode][classification.complexity];

  // Step 3: Check harness availability
  const harness = await getAvailableHarness(
    selection.harness,
    config.fallbackOrder
  );

  // Step 4: Calculate estimated cost
  const modelProfile = getModelProfile(harness, selection.model);
  const estimatedTokens = estimateTokens(task);
  const estimatedCost = calculateCost(modelProfile, estimatedTokens);

  return {
    harness,
    model: selection.model,
    complexity: classification.complexity,
    mode: config.defaultMode,
    estimatedCost,
    reasoning: `${classification.reasoning}. Routed to ${harness}/${selection.model}`,
  };
}
```

### 4.2 Cascade/Escalation Logic (src/routing/cascade.ts)

```typescript
interface EscalationResult {
  success: boolean;
  finalHarness: HarnessName;
  finalModel: string;
  attempts: number;
  escalations: EscalationStep[];
}

interface EscalationStep {
  attempt: number;
  harness: HarnessName;
  model: string;
  result: "success" | "failure" | "rate_limited";
  error?: string;
}

async function executeWithCascade(
  task: UserStory,
  initialRouting: RoutingDecision,
  config: AutoModeConfig
): Promise<EscalationResult> {
  const escalations: EscalationStep[] = [];
  let currentHarness = initialRouting.harness;
  let currentModel = initialRouting.model;
  let attempt = 0;

  while (attempt < config.escalation.maxAttempts) {
    attempt++;

    try {
      // Try execution
      const result = await executeTask(task, currentHarness, currentModel);

      if (result.success) {
        escalations.push({
          attempt,
          harness: currentHarness,
          model: currentModel,
          result: "success",
        });

        return {
          success: true,
          finalHarness: currentHarness,
          finalModel: currentModel,
          attempts: attempt,
          escalations,
        };
      }

      // Task failed - escalate
      escalations.push({
        attempt,
        harness: currentHarness,
        model: currentModel,
        result: "failure",
        error: result.error,
      });

      // Get next model in escalation path
      const nextModel = config.escalation.escalationPath[currentModel];
      if (nextModel) {
        currentModel = nextModel;
        currentHarness = getHarnessForModel(nextModel);
      } else {
        // No more escalation - try next harness
        const fallbackIdx = config.fallbackOrder.indexOf(currentHarness);
        if (fallbackIdx < config.fallbackOrder.length - 1) {
          currentHarness = config.fallbackOrder[fallbackIdx + 1];
          currentModel = getDefaultModelForHarness(currentHarness);
        } else {
          break; // No more fallbacks
        }
      }

    } catch (error) {
      if (isRateLimitError(error)) {
        escalations.push({
          attempt,
          harness: currentHarness,
          model: currentModel,
          result: "rate_limited",
          error: error.message,
        });

        // Skip to next harness
        const fallbackIdx = config.fallbackOrder.indexOf(currentHarness);
        if (fallbackIdx < config.fallbackOrder.length - 1) {
          currentHarness = config.fallbackOrder[fallbackIdx + 1];
          currentModel = getDefaultModelForHarness(currentHarness);
        } else {
          break;
        }
      } else {
        throw error;
      }
    }
  }

  return {
    success: false,
    finalHarness: currentHarness,
    finalModel: currentModel,
    attempts: attempt,
    escalations,
  };
}
```

---

## Part 5: Review Micro-Tasks System

### 5.1 Micro-Task Design (src/review/tasks/)

Each micro-task is designed to:
- Complete in a single harness session (prevents context compaction)
- Report issues immediately
- Queue fix tasks before proceeding
- Be independently testable

#### Typecheck Task (src/review/tasks/typecheck.ts)
```typescript
interface TypecheckResult {
  success: boolean;
  errorCount: number;
  errors: TypecheckError[];
  fixTasks: FixTask[];
}

async function runTypecheckReview(options: ReviewOptions): Promise<TypecheckResult> {
  // Step 1: Run typecheck
  const result = await runCommand("bun run typecheck");

  // Step 2: Parse errors
  const errors = parseTypecheckErrors(result.stderr);

  // Step 3: Generate fix tasks
  const fixTasks = errors.map(error => ({
    type: "typecheck_fix",
    file: error.file,
    line: error.line,
    description: `Fix TypeScript error: ${error.message}`,
    priority: "high",
  }));

  return {
    success: errors.length === 0,
    errorCount: errors.length,
    errors,
    fixTasks,
  };
}
```

#### Lint Task (src/review/tasks/lint.ts)
```typescript
interface LintResult {
  success: boolean;
  warningCount: number;
  errorCount: number;
  issues: LintIssue[];
  fixTasks: FixTask[];
}

async function runLintReview(options: ReviewOptions): Promise<LintResult> {
  // Step 1: Run lint
  const result = await runCommand("bun run lint");

  // Step 2: Parse issues
  const issues = parseLintOutput(result.stdout);

  // Step 3: Generate fix tasks (errors only, warnings logged)
  const fixTasks = issues
    .filter(i => i.severity === "error")
    .map(issue => ({
      type: "lint_fix",
      file: issue.file,
      line: issue.line,
      rule: issue.rule,
      description: `Fix lint error [${issue.rule}]: ${issue.message}`,
      priority: "high",
    }));

  return {
    success: issues.filter(i => i.severity === "error").length === 0,
    warningCount: issues.filter(i => i.severity === "warning").length,
    errorCount: issues.filter(i => i.severity === "error").length,
    issues,
    fixTasks,
  };
}
```

#### Test Task (src/review/tasks/test.ts)
```typescript
interface TestResult {
  success: boolean;
  totalTests: number;
  passedTests: number;
  failedTests: number;
  failures: TestFailure[];
  fixTasks: FixTask[];
}

async function runTestReview(options: ReviewOptions): Promise<TestResult> {
  // Step 1: Run tests
  const result = await runCommand("bun test --reporter=json");

  // Step 2: Parse results
  const testOutput = parseTestOutput(result.stdout);

  // Step 3: Generate fix tasks for failures
  const fixTasks = testOutput.failures.map(failure => ({
    type: "test_fix",
    file: failure.testFile,
    testName: failure.testName,
    description: `Fix failing test: ${failure.testName}`,
    error: failure.error,
    priority: "high",
  }));

  return {
    success: testOutput.failures.length === 0,
    totalTests: testOutput.total,
    passedTests: testOutput.passed,
    failedTests: testOutput.failures.length,
    failures: testOutput.failures,
    fixTasks,
  };
}
```

#### Security Task (src/review/tasks/security.ts)
```typescript
interface SecurityResult {
  success: boolean;
  vulnerabilities: SecurityVulnerability[];
  fixTasks: FixTask[];
}

const SECURITY_CHECKS = [
  { pattern: /password\s*=\s*["'][^"']+["']/gi, type: "hardcoded_password" },
  { pattern: /api[_-]?key\s*[:=]\s*["'][^"']+["']/gi, type: "hardcoded_api_key" },
  { pattern: /eval\s*\(/gi, type: "unsafe_eval" },
  { pattern: /innerHTML\s*=/gi, type: "xss_risk" },
  { pattern: /exec\s*\(/gi, type: "command_injection_risk" },
];

async function runSecurityReview(options: ReviewOptions): Promise<SecurityResult> {
  // Step 1: Scan changed files for patterns
  const changedFiles = await getChangedFiles();
  const vulnerabilities: SecurityVulnerability[] = [];

  for (const file of changedFiles) {
    const content = await readFile(file);
    for (const check of SECURITY_CHECKS) {
      const matches = content.match(check.pattern);
      if (matches) {
        vulnerabilities.push({
          file,
          type: check.type,
          matches: matches.length,
          severity: getSeverity(check.type),
        });
      }
    }
  }

  // Step 2: Generate fix tasks
  const fixTasks = vulnerabilities
    .filter(v => v.severity === "critical" || v.severity === "high")
    .map(v => ({
      type: "security_fix",
      file: v.file,
      description: `Fix security issue [${v.type}]: ${v.matches} occurrence(s)`,
      priority: "critical",
    }));

  return {
    success: vulnerabilities.filter(v => v.severity !== "info").length === 0,
    vulnerabilities,
    fixTasks,
  };
}
```

#### Quality Task (src/review/tasks/quality.ts)
```typescript
interface QualityResult {
  success: boolean;
  issues: QualityIssue[];
  fixTasks: FixTask[];
}

async function runQualityReview(options: ReviewOptions): Promise<QualityResult> {
  const issues: QualityIssue[] = [];
  const changedFiles = await getChangedFiles();

  for (const file of changedFiles) {
    // Check for dead code (unused exports)
    const deadCode = await detectDeadCode(file);
    issues.push(...deadCode);

    // Check for code duplication
    const duplicates = await detectDuplication(file);
    issues.push(...duplicates);

    // Check for excessive complexity
    const complexity = await analyzeComplexity(file);
    if (complexity.score > 10) {
      issues.push({
        file,
        type: "high_complexity",
        message: `Function complexity score: ${complexity.score}`,
        suggestion: "Consider breaking into smaller functions",
      });
    }
  }

  // Generate fix tasks for actionable issues
  const fixTasks = issues
    .filter(i => i.type === "dead_code" || i.type === "high_complexity")
    .map(i => ({
      type: "quality_fix",
      file: i.file,
      description: `Fix quality issue: ${i.message}`,
      priority: "medium",
    }));

  return {
    success: issues.filter(i => i.type === "dead_code").length === 0,
    issues,
    fixTasks,
  };
}
```

#### Docs Task (src/review/tasks/docs.ts)
```typescript
interface DocsResult {
  success: boolean;
  issues: DocsIssue[];
  fixTasks: FixTask[];
}

async function runDocsReview(options: ReviewOptions): Promise<DocsResult> {
  const issues: DocsIssue[] = [];

  // Check if README needs update
  const changedFiles = await getChangedFiles();
  const hasNewExports = changedFiles.some(f => f.includes("index.ts"));
  const hasNewCommands = changedFiles.some(f => f.includes("cli/"));

  if (hasNewExports || hasNewCommands) {
    // Check if README was updated
    const readmeChanged = changedFiles.includes("README.md");
    if (!readmeChanged) {
      issues.push({
        type: "missing_readme_update",
        message: "New exports or commands added but README not updated",
        files: changedFiles.filter(f => f.includes("index.ts") || f.includes("cli/")),
      });
    }
  }

  // Check for missing JSDoc on exported functions
  const missingDocs = await findMissingJSDoc(changedFiles);
  issues.push(...missingDocs);

  const fixTasks = issues.map(i => ({
    type: "docs_fix",
    description: `Update documentation: ${i.message}`,
    priority: "low",
  }));

  return {
    success: issues.filter(i => i.type === "missing_readme_update").length === 0,
    issues,
    fixTasks,
  };
}
```

### 5.2 Micro-Task Runner (src/review/runner.ts)

```typescript
interface ReviewRunnerOptions {
  mode: Mode;
  tasks: ReviewTaskType[];
  maxRetries: number;
  stopOnFailure: boolean;
}

interface ReviewSummary {
  success: boolean;
  tasksRun: number;
  tasksPassed: number;
  tasksFailed: number;
  fixTasksGenerated: FixTask[];
  results: Record<ReviewTaskType, ReviewTaskResult>;
}

async function runReviewPipeline(options: ReviewRunnerOptions): Promise<ReviewSummary> {
  const results: Record<string, ReviewTaskResult> = {};
  const allFixTasks: FixTask[] = [];

  for (const taskType of options.tasks) {
    // Each micro-task runs in fresh harness session
    console.log(`\nðŸ” Running ${taskType} review...`);

    const task = REVIEW_TASKS[taskType];
    const result = await runInFreshSession(task, options.mode);

    results[taskType] = result;
    allFixTasks.push(...result.fixTasks);

    // Report immediately
    if (result.success) {
      console.log(`âœ… ${taskType}: PASSED`);
    } else {
      console.log(`âŒ ${taskType}: FAILED (${result.fixTasks.length} fixes needed)`);

      // Queue fixes immediately
      if (result.fixTasks.length > 0) {
        await queueFixTasks(result.fixTasks);
      }

      if (options.stopOnFailure) {
        break;
      }
    }
  }

  const tasksPassed = Object.values(results).filter(r => r.success).length;

  return {
    success: tasksPassed === options.tasks.length,
    tasksRun: Object.keys(results).length,
    tasksPassed,
    tasksFailed: Object.keys(results).length - tasksPassed,
    fixTasksGenerated: allFixTasks,
    results,
  };
}

// Run task in isolated harness session
async function runInFreshSession(
  task: ReviewTask,
  mode: Mode
): Promise<ReviewTaskResult> {
  // Get appropriate model for review (usually SOTA for quality)
  const routing = getReviewRouting(mode);

  // Create isolated prompt for this micro-task only
  const prompt = generateMicroTaskPrompt(task);

  // Execute in fresh session
  const adapter = getAdapter(routing.harness);
  const result = await adapter.invoke(prompt, { model: routing.model });

  return parseReviewResult(result.output);
}
```

---

## Part 6: PRD.json Schema Extension

### 6.1 Extended Story Schema

```typescript
interface ExtendedUserStory {
  // Existing fields
  id: string;
  title: string;
  description: string;
  acceptanceScenarios: string[];
  passes: boolean;

  // NEW: Routing metadata
  routing?: {
    complexity: Complexity;
    harness: HarnessName;
    model: string;
    mode: Mode;
    estimatedCost: number;
    classificationReasoning: string;
  };

  // NEW: Execution history
  execution?: {
    attempts: number;
    escalations: EscalationStep[];
    actualCost: number;
    actualHarness: HarnessName;
    actualModel: string;
  };
}
```

### 6.2 Example prd.json with Routing

```json
{
  "feature": "Smart Auto Model Routing",
  "mode": "good",
  "stories": [
    {
      "id": "US-001",
      "title": "Enable Auto Mode During Init",
      "description": "Add auto mode opt-in during relentless init",
      "acceptanceScenarios": [
        "Given new project, When user runs init, Then asked about auto mode"
      ],
      "passes": false,
      "routing": {
        "complexity": "medium",
        "harness": "claude",
        "model": "sonnet-4.5",
        "mode": "good",
        "estimatedCost": 0.15,
        "classificationReasoning": "Config modification with user prompts - medium complexity"
      }
    },
    {
      "id": "US-002",
      "title": "Task Complexity Classification",
      "description": "Classify each task by complexity during planning",
      "acceptanceScenarios": [
        "Given simple task, When analyzed, Then classified as simple"
      ],
      "passes": false,
      "routing": {
        "complexity": "complex",
        "harness": "claude",
        "model": "opus-4.5",
        "mode": "good",
        "estimatedCost": 0.45,
        "classificationReasoning": "Requires LLM integration and heuristic design - complex"
      }
    }
  ]
}
```

---

## Part 7: Testing Strategy

### 7.1 Unit Tests

**Complexity Classifier (tests/routing/classifier.test.ts)**
```typescript
describe("classifyTask", () => {
  it("classifies typo fix as simple with high confidence", async () => {
    const task = { title: "Fix typo in README", description: "..." };
    const result = await classifyTask(task);
    expect(result.complexity).toBe("simple");
    expect(result.confidence).toBeGreaterThan(0.8);
    expect(result.usedLLM).toBe(false);
  });

  it("classifies OAuth implementation as complex", async () => {
    const task = { title: "Implement OAuth2 authentication", description: "..." };
    const result = await classifyTask(task);
    expect(result.complexity).toBe("complex");
  });

  it("uses LLM when heuristics are ambiguous", async () => {
    const task = { title: "Update user preferences", description: "..." };
    const result = await classifyTask(task);
    expect(result.usedLLM).toBe(true);
  });
});
```

**Router (tests/routing/router.test.ts)**
```typescript
describe("routeTask", () => {
  it("routes simple task in free mode to GLM-4.7", async () => {
    const config = { defaultMode: "free", fallbackOrder: [...] };
    const task = { title: "Fix typo", complexity: "simple" };
    const routing = await routeTask(task, config);
    expect(routing.harness).toBe("opencode");
    expect(routing.model).toBe("glm-4.7");
  });

  it("routes complex task in genius mode to Opus", async () => {
    const config = { defaultMode: "genius", fallbackOrder: [...] };
    const task = { title: "Redesign auth", complexity: "complex" };
    const routing = await routeTask(task, config);
    expect(routing.harness).toBe("claude");
    expect(routing.model).toBe("opus-4.5");
  });
});
```

**Cascade (tests/routing/cascade.test.ts)**
```typescript
describe("executeWithCascade", () => {
  it("escalates from Haiku to Sonnet on failure", async () => {
    // Mock Haiku failure
    mockAdapter("claude", "haiku-4.5", { success: false });
    mockAdapter("claude", "sonnet-4.5", { success: true });

    const result = await executeWithCascade(task, initialRouting, config);
    expect(result.success).toBe(true);
    expect(result.attempts).toBe(2);
    expect(result.finalModel).toBe("sonnet-4.5");
  });

  it("falls back to next harness on rate limit", async () => {
    // Mock Claude rate limit
    mockAdapter("claude", "opus-4.5", { rateLimited: true });
    mockAdapter("codex", "gpt-5.2-high", { success: true });

    const result = await executeWithCascade(task, initialRouting, config);
    expect(result.success).toBe(true);
    expect(result.finalHarness).toBe("codex");
  });
});
```

### 7.2 Integration Tests

**Auto-Mode E2E (tests/integration/auto-mode.test.ts)**
```typescript
describe("Auto Mode Integration", () => {
  it("completes feature with cost savings", async () => {
    const result = await runFeature({
      feature: "test-feature",
      mode: "cheap",
      stories: [...],
    });

    expect(result.success).toBe(true);
    expect(result.costSavings).toBeGreaterThan(0.5); // 50%+ savings
    expect(result.escalationRate).toBeLessThan(0.15); // <15% escalations
  });

  it("runs review micro-tasks in isolation", async () => {
    const result = await runReviewPipeline({
      mode: "good",
      tasks: ["typecheck", "lint", "test"],
    });

    // Each task should have run in separate session
    expect(result.tasksRun).toBe(3);
    expect(result.sessionCount).toBe(3); // One per task
  });
});
```

---

## Part 8: Rollout Plan

### 8.1 Phased Implementation

**Phase 1: Foundation (Stories 1-3)**
- Harness adapter model selection updates
- Configuration schema extensions
- Basic routing logic

**Phase 2: Intelligence (Story 4-5)**
- Model registry with costs/capabilities
- Hybrid complexity classifier
- Cost estimation

**Phase 3: Resilience (Story 6)**
- Cascade/escalation logic
- Rate limit handling
- Fallback chains

**Phase 4: Quality (Story 7, 7a)**
- Review micro-tasks
- Issue reporting
- Fix task queueing

**Phase 5: Polish (Story 8)**
- Documentation updates
- CLI help text
- Cost savings marketing

### 8.2 Migration Strategy

- **Backward Compatible**: Auto mode is opt-in, existing workflows unchanged
- **No Data Migration**: New config fields have defaults
- **Gradual Rollout**: Start with beta flag, promote to default over time

### 8.3 Monitoring

- Log all routing decisions to progress.txt
- Track escalation rate per project
- Monitor cost savings vs baseline
- Alert on >20% escalation rate

---

## Appendix A: Complete Model Registry

```typescript
const MODEL_REGISTRY: ModelProfile[] = [
  // Claude
  {
    id: "opus-4.5",
    displayName: "Claude Opus 4.5",
    harness: "claude",
    tier: "sota",
    inputCost: 5.0,
    outputCost: 25.0,
    sweBenchScore: 80.9,
    contextWindow: 200000,
    strengths: ["code_review", "architecture", "debugging", "final_review"],
    limitations: ["expensive", "slower_start"],
    cliFlag: "--model",
    cliValue: "claude-opus-4-5-20251101",
  },
  {
    id: "sonnet-4.5",
    displayName: "Claude Sonnet 4.5",
    harness: "claude",
    tier: "standard",
    inputCost: 3.0,
    outputCost: 15.0,
    contextWindow: 200000,
    strengths: ["frontend", "refactoring", "daily_coding"],
    limitations: [],
    cliFlag: "--model",
    cliValue: "claude-sonnet-4-5-20251020",
  },
  {
    id: "haiku-4.5",
    displayName: "Claude Haiku 4.5",
    harness: "claude",
    tier: "cheap",
    inputCost: 1.0,
    outputCost: 5.0,
    sweBenchScore: 73.0,
    contextWindow: 200000,
    tokensPerSecond: 200,
    strengths: ["prototyping", "scaffolding", "simple_tasks"],
    limitations: ["less_reasoning"],
    cliFlag: "--model",
    cliValue: "claude-haiku-4-5-20251022",
  },

  // Codex (OpenAI)
  {
    id: "gpt-5.2-high",
    displayName: "GPT-5.2 (reasoning-effort high)",
    harness: "codex",
    tier: "sota",
    inputCost: 1.75,
    outputCost: 14.0,
    sweBenchScore: 80.0,
    strengths: ["reasoning", "control_flow", "overnight_runs"],
    limitations: [],
    cliFlag: "--model",
    cliValue: "gpt-5.2",
    cliArgs: ["-c", "reasoning_effort=\"high\""],
  },
  {
    id: "gpt-5.2-xhigh",
    displayName: "GPT-5.2 (reasoning-effort xhigh)",
    harness: "codex",
    tier: "sota",
    inputCost: 1.75,
    outputCost: 14.0,
    sweBenchScore: 80.0,
    contextWindow: 128000,
    strengths: ["deep_reasoning", "complex_logic", "long_horizon_tasks"],
    limitations: [],
    cliFlag: "--model",
    cliValue: "gpt-5.2",
    cliArgs: ["-c", "reasoning_effort=\"xhigh\""],
  },
  {
    id: "gpt-5.2-medium",
    displayName: "GPT-5.2 (reasoning-effort medium)",
    harness: "codex",
    tier: "standard",
    inputCost: 1.25,
    outputCost: 10.0,
    strengths: ["balanced", "good_review"],
    limitations: [],
    cliFlag: "--model",
    cliValue: "gpt-5.2",
    cliArgs: ["-c", "reasoning_effort=\"medium\""],
  },
  {
    id: "gpt-5.2-low",
    displayName: "GPT-5.2 (reasoning-effort low)",
    harness: "codex",
    tier: "cheap",
    inputCost: 0.75,
    outputCost: 6.0,
    strengths: ["fast", "simple_tasks"],
    limitations: ["less_accuracy"],
    cliFlag: "--model",
    cliValue: "gpt-5.2",
    cliArgs: ["-c", "reasoning_effort=\"low\""],
  },

  // Droid
  {
    id: "gpt-5.2",
    displayName: "GPT-5.2 (via Droid)",
    harness: "droid",
    tier: "standard",
    inputCost: 1.25,
    outputCost: 10.0,
    strengths: ["balanced", "general_coding"],
    limitations: [],
    cliFlag: "-m",
    cliValue: "gpt-5.2",
  },
  {
    id: "droid-claude-sonnet-4-5-20250929",
    displayName: "Claude 3.5 Sonnet (via Droid)",
    harness: "droid",
    tier: "standard",
    inputCost: 2.0,  // 2.0x multiplier
    outputCost: 10.0,
    strengths: ["balanced", "good_quality"],
    limitations: [],
    cliFlag: "-m",
    cliValue: "claude-sonnet-4-5-20250929",
  },
  {
    id: "gpt-5.1-codex",
    displayName: "GPT-5.1 Codex (via Droid)",
    harness: "droid",
    tier: "standard",
    inputCost: 1.0,
    outputCost: 8.0,
    strengths: ["coding", "refactoring"],
    limitations: [],
    cliFlag: "-m",
    cliValue: "gpt-5.1-codex",
  },

  // OpenCode Zen (Free)
  {
    id: "glm-4.7",
    displayName: "GLM-4.7",
    harness: "opencode",
    tier: "free",
    inputCost: 0.0,
    outputCost: 0.0,
    sweBenchScore: 73.8,
    strengths: ["multilingual", "backend", "tool_use", "agentic"],
    limitations: ["complex_ui"],
    cliFlag: "--model",
    cliValue: "glm-4.7",
  },
  {
    id: "grok-code-fast-1",
    displayName: "Grok Code Fast 1",
    harness: "opencode",
    tier: "free",
    inputCost: 0.0,
    outputCost: 0.0,
    tokensPerSecond: 92,
    strengths: ["speed", "tool_calling", "agentic", "bug_fixes"],
    limitations: ["tailwind_v3"],
    cliFlag: "--model",
    cliValue: "grok-code-fast-1",
  },
  {
    id: "minimax-m2.1",
    displayName: "MiniMax M2.1",
    harness: "opencode",
    tier: "free",
    inputCost: 0.0,
    outputCost: 0.0,
    strengths: ["fullstack", "web_mobile", "reviews"],
    limitations: ["newer_less_docs"],
    cliFlag: "--model",
    cliValue: "minimax-m2.1",
  },

  // Amp
  {
    id: "amp-free",
    displayName: "Amp Free",
    harness: "amp",
    tier: "free",
    inputCost: 0.0,
    outputCost: 0.0,
    strengths: ["interactive", "refactoring", "smart_mode"],
    limitations: ["context_caps", "no_execute_mode", "ads"],
    cliFlag: "-m",
    cliValue: "free",
  },

  // Gemini
  {
    id: "gemini-3-pro",
    displayName: "Gemini 3 Pro",
    harness: "gemini",
    tier: "premium",
    inputCost: 3.0,
    outputCost: 15.0,
    contextWindow: 1000000,
    strengths: ["frontend_ui", "webdev_arena_leader", "algorithms"],
    limitations: [],
    cliFlag: "--model",
    cliValue: "gemini-3-pro",
  },
  {
    id: "gemini-3-flash",
    displayName: "Gemini 3 Flash",
    harness: "gemini",
    tier: "cheap",
    inputCost: 0.5,
    outputCost: 3.0,
    contextWindow: 1000000,
    strengths: ["fast", "long_context", "simple_tasks"],
    limitations: [],
    cliFlag: "--model",
    cliValue: "gemini-3-flash",
  },
];
```

---

## Appendix B: CLI Examples

```bash
# Basic usage with default mode (good)
relentless run --feature auth

# Explicit mode selection
relentless run --feature auth --mode free      # Maximize free models
relentless run --feature auth --mode cheap     # Optimize for cost
relentless run --feature auth --mode good      # Balanced (default)
relentless run --feature auth --mode genius    # Use SOTA everywhere

# Custom fallback order
relentless run --feature auth --fallback-order "opencode,droid,claude"

# Review options
relentless run --feature auth --skip-review           # Skip final review
relentless run --feature auth --review-mode genius    # Use SOTA for review

# Combined options
relentless run --feature auth \
  --mode cheap \
  --fallback-order "droid,claude,codex" \
  --review-mode good

# Show estimated costs before execution
relentless estimate --feature auth --mode cheap

# View routing decisions
relentless explain --feature auth  # Shows why each task was routed
```

---

## Next Steps

1. Run `/relentless.tasks` to generate user stories and detailed tasks
2. Implement Phase 1 (harness adapter updates)
3. Add comprehensive test coverage
4. Iterate through remaining phases

---

*This plan implements Constitution Principles 2, 5, 6 (Smart Routing, Final Review, Agent-Aware) and aligns with TDD requirements (Principle 1).*
